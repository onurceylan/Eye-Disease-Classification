{"cells":[{"cell_type":"markdown","metadata":{"id":"CKeVGxZ5GG6o"},"source":["# Import needed modules"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-02-22T12:11:04.006137Z","iopub.status.busy":"2025-02-22T12:11:04.005890Z","iopub.status.idle":"2025-02-22T12:11:04.031586Z","shell.execute_reply":"2025-02-22T12:11:04.030966Z","shell.execute_reply.started":"2025-02-22T12:11:04.006112Z"},"trusted":true},"outputs":[],"source":["#!pip install tensorflow==2.9.1"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:14:29.978575Z","iopub.status.busy":"2025-02-24T13:14:29.978281Z","iopub.status.idle":"2025-02-24T13:14:35.308764Z","shell.execute_reply":"2025-02-24T13:14:35.307652Z","shell.execute_reply.started":"2025-02-24T13:14:29.978545Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2025.0.1)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (1.2.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:14:35.309944Z","iopub.status.busy":"2025-02-24T13:14:35.309695Z","iopub.status.idle":"2025-02-24T13:14:49.803678Z","shell.execute_reply":"2025-02-24T13:14:49.802903Z","shell.execute_reply.started":"2025-02-24T13:14:35.309921Z"},"id":"CeMcAy_5GG6s","outputId":"8e007371-6c2c-492c-99bb-172286922ae2","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["modules loaded\n"]}],"source":["# import system libs\n","import os\n","import time\n","import shutil\n","import pathlib\n","import itertools\n","\n","# import data handling tools\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# import Deep learning Libraries\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import Adam, Adamax\n","from tensorflow.keras.metrics import categorical_crossentropy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization, Layer \n","from tensorflow.keras import regularizers\n","from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n","\n","# Ignore Warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","print ('modules loaded')"]},{"cell_type":"markdown","metadata":{"id":"SA_gwvwnGG6v"},"source":["# Create needed functions"]},{"cell_type":"markdown","metadata":{"id":"e4reLHLHabWD"},"source":["## Functions to Create Data Frame from Dataset"]},{"cell_type":"markdown","metadata":{"id":"JQdhl_CRGG6v"},"source":["#### **Function to create data frame**"]},{"cell_type":"markdown","metadata":{"id":"JZaHdeFxGG6x"},"source":["#### Function to generate images from dataframe"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:14:49.805710Z","iopub.status.busy":"2025-02-24T13:14:49.805160Z","iopub.status.idle":"2025-02-24T13:14:49.812115Z","shell.execute_reply":"2025-02-24T13:14:49.811282Z","shell.execute_reply.started":"2025-02-24T13:14:49.805684Z"},"id":"g2nDmYaAabWE","trusted":true},"outputs":[],"source":["# Generate data paths with labels\n","def define_paths(data_dir):\n","    filepaths = []\n","    labels = []\n","\n","    folds = os.listdir(data_dir)\n","    for fold in folds:\n","        foldpath = os.path.join(data_dir, fold)\n","        filelist = os.listdir(foldpath)\n","        for file in filelist:\n","            fpath = os.path.join(foldpath, file)\n","            filepaths.append(fpath)\n","            labels.append(fold)\n","\n","    return filepaths, labels\n","\n","\n","# Concatenate data paths with labels into one dataframe ( to later be fitted into the model )\n","def define_df(files, classes):\n","    Fseries = pd.Series(files, name= 'filepaths')\n","    Lseries = pd.Series(classes, name='labels')\n","    return pd.concat([Fseries, Lseries], axis= 1)\n","\n","# Split dataframe to train, valid, and test\n","def split_data(data_dir):\n","    # train dataframe\n","    files, classes = define_paths(data_dir)\n","    df = define_df(files, classes)\n","    strat = df['labels']\n","    train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123, stratify= strat)\n","\n","    # valid and test dataframe\n","    strat = dummy_df['labels']\n","    valid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state= 123, stratify= strat)\n","\n","    return train_df, valid_df, test_df"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:14:49.813530Z","iopub.status.busy":"2025-02-24T13:14:49.813266Z","iopub.status.idle":"2025-02-24T13:14:49.868653Z","shell.execute_reply":"2025-02-24T13:14:49.867848Z","shell.execute_reply.started":"2025-02-24T13:14:49.813509Z"},"id":"iLL8hHQcGG6x","trusted":true},"outputs":[],"source":["def create_gens (train_df, valid_df, test_df, batch_size):\n","    '''\n","    This function takes train, validation, and test dataframe and fit them into image data generator, because model takes data from image data generator.\n","    Image data generator converts images into tensors. '''\n","\n","\n","    # define model parameters\n","    img_size = (224, 224)\n","    channels = 3 # either BGR or Grayscale\n","    color = 'rgb'\n","    img_shape = (img_size[0], img_size[1], channels)\n","\n","    # Recommended : use custom function for test data batch size, else we can use normal batch size.\n","    ts_length = len(test_df)\n","    test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","    test_steps = ts_length // test_batch_size\n","\n","    # This function which will be used in image data generator for data augmentation, it just take the image and return it again.\n","    def scalar(img):\n","        return img\n","\n","    tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n","    ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n","\n","    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n","                                        color_mode= color, shuffle= True, batch_size= batch_size)\n","\n","    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n","                                        color_mode= color, shuffle= True, batch_size= batch_size)\n","\n","    # Note: we will use custom test_batch_size, and make shuffle= false\n","    test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n","                                        color_mode= color, shuffle= False, batch_size= test_batch_size)\n","\n","    return train_gen, valid_gen, test_gen"]},{"cell_type":"markdown","metadata":{"id":"8ifXox4SGG6y"},"source":["#### **Function to display data sample**"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:14:49.871839Z","iopub.status.busy":"2025-02-24T13:14:49.871531Z","iopub.status.idle":"2025-02-24T13:14:49.889208Z","shell.execute_reply":"2025-02-24T13:14:49.888431Z","shell.execute_reply.started":"2025-02-24T13:14:49.871809Z"},"id":"IAGbj3ZyGG6y","trusted":true},"outputs":[],"source":["def show_images(gen):\n","    '''\n","    This function take the data generator and show sample of the images\n","    '''\n","\n","    # return classes , images to be displayed\n","    g_dict = gen.class_indices        # defines dictionary {'class': index}\n","    classes = list(g_dict.keys())     # defines list of dictionary's kays (classes), classes names : string\n","    images, labels = next(gen)        # get a batch size samples from the generator\n","\n","    # calculate number of displayed samples\n","    length = len(labels)        # length of batch size\n","    sample = min(length, 25)    # check if sample less than 25 images\n","\n","    plt.figure(figsize= (20, 20))\n","\n","    for i in range(sample):\n","        plt.subplot(5, 5, i + 1)\n","        image = images[i] / 255       # scales data to range (0 - 255)\n","        plt.imshow(image)\n","        index = np.argmax(labels[i])  # get image index\n","        class_name = classes[index]   # get class of image\n","        plt.title(class_name, color= 'blue', fontsize= 12)\n","        plt.axis('off')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"_K-ryg0DGG6z"},"source":["#### **Callbacks** \n","<br> \n","Callbacks : Helpful functions to help optimize model training  <br> \n","Examples: stop model training after specfic time, stop training if no improve in accuracy and so on."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:14:49.890224Z","iopub.status.busy":"2025-02-24T13:14:49.889971Z","iopub.status.idle":"2025-02-24T13:14:49.909450Z","shell.execute_reply":"2025-02-24T13:14:49.908628Z","shell.execute_reply.started":"2025-02-24T13:14:49.890205Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import time\n","\n","class MyCallback(tf.keras.callbacks.Callback):\n","    # MyCallback sınıfını başlatır, eğitim sırasında kullanılacak parametreleri tanımlar\n","    def __init__(self, model, patience, stop_patience, threshold, factor, batches, epochs, ask_epoch):\n","        super(MyCallback, self).__init__()\n","        # Sabır değeri, öğrenme oranını düşürmeden önce kaç epoch beklenir\n","        self.patience = patience\n","        # Erken durdurma için sabır değeri, öğrenme oranı iyileşmezse eğitimi durdurmak için epoch sayısı\n","        self.stop_patience = stop_patience\n","        # Eğitim doğruluğu eşiği, bu eşikten düşükse accuracy izlenir, yüksekse val_loss izlenir\n","        self.threshold = threshold\n","        # Öğrenme oranını azaltma faktörü (örneğin, 0.5 ile yarıya indirir)\n","        self.factor = float(factor)\n","        # Her epoch'ta işlenecek batch sayısı\n","        self.batches = batches\n","        # Toplam eğitim epoch sayısı\n","        self.epochs = epochs\n","        # Kullanıcıya eğitimi durdurup durdurmayacağını sormak için epoch aralığı\n","        self.ask_epoch = ask_epoch\n","        # Başlangıç ask_epoch değerini saklar\n","        self.ask_epoch_initial = ask_epoch\n","        # En iyi ağırlıkları saklamak için\n","        self.best_weights = None\n","        # İlk ağırlıkları saklamak için\n","        self.initial_weights = None\n","        # En iyi performansı gösteren epoch numarası\n","        self.best_epoch = 1\n","        # Başlangıç öğrenme oranını modelden alır\n","        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.learning_rate))\n","        # En yüksek eğitim doğruluğu\n","        self.highest_tracc = 0.0\n","        # En düşük doğrulama kaybı\n","        self.lowest_vloss = float('inf')\n","        # Öğrenme oranı azaltma sayacı\n","        self.count = 0\n","        # Erken durdurma sayacı\n","        self.stop_count = 0\n","\n","    # Sınıfın yapılandırmasını JSON'a dönüştürür, model kaydetme/yükleme için\n","    def get_config(self):\n","        config = {\n","            'patience': self.patience,\n","            'stop_patience': self.stop_patience,\n","            'threshold': self.threshold,\n","            'factor': self.factor,\n","            'batches': self.batches,\n","            'epochs': self.epochs,\n","            'ask_epoch': self.ask_epoch,\n","            'initial_lr': self.initial_lr,\n","        }\n","        return config\n","\n","    # JSON'dan sınıfı yeniden oluşturur\n","    @classmethod\n","    def from_config(cls, config):\n","        return cls(**config)\n","\n","    # Eğitim başladığında çağrılır, başlığı ve başlangıç zamanını ayarlar\n","    def on_train_begin(self, logs=None):\n","        # Eğitim sonuçlarını göstermek için başlık formatı\n","        msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format(\n","            'Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor', '% Improv', 'Duration'\n","        )\n","        print(msg)\n","        # Eğitim başlangıç zamanını kaydeder\n","        self.start_time = time.time()\n","        # İlk ağırlıkları alır ve saklar\n","        self.initial_weights = self.model.get_weights()\n","        print(f\"Training started. Initial learning rate: {self.initial_lr}\")\n","\n","    # Eğitim bittiğinde çağrılır, süreyi ve en iyi ağırlıkları geri yükler\n","    def on_train_end(self, logs=None):\n","        # Eğitim sonlanma zamanını alır\n","        stop_time = time.time()\n","        # Eğitim süresini hesaplar\n","        tr_duration = stop_time - self.start_time\n","        # Süreyi saat, dakika ve saniye olarak ayırır\n","        hours = tr_duration // 3600\n","        minutes = (tr_duration - (hours * 3600)) // 60\n","        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n","        # Süreyi yazdırır\n","        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n","        print(msg)\n","        # En iyi ağırlıkları modelde geri yükler\n","        if self.best_weights is not None:\n","            self.model.set_weights(self.best_weights)\n","            print(f\"Best weights restored from epoch {self.best_epoch}\")\n","\n","    # Her batch sonunda çağrılır, batch işlem durumunu yazdırır\n","    def on_train_batch_end(self, batch, logs=None):\n","        # Batch doğruluğunu ve kaybını alır\n","        acc = logs.get('accuracy', 0.0) * 100\n","        loss = logs.get('loss', float('inf'))\n","        # Batch işlemini yazdırır, \\r ile aynı satırda günceller\n","        msg = '{0:20s}processing batch {1:} of {2:5s}-   accuracy=  {3:5.3f}   -   loss: {4:8.5f}'.format(\n","            ' ', str(batch), str(self.batches), acc, loss\n","        )\n","        print(msg, '\\r', end='')\n","\n","    # Her epoch başladığında çağrılır, epoch başlangıç zamanını ayarlar\n","    def on_epoch_begin(self, epoch, logs=None):\n","        self.ep_start = time.time()\n","        # Epoch numarasını ve toplam epoch sayısını yazdırır\n","        print(f\"Epoch {epoch + 1}/{self.epochs} started\")\n","\n","    # Her epoch sonunda çağrılır, metrikleri izler ve öğrenme oranını günceller\n","    def on_epoch_end(self, epoch, logs=None):\n","        # Epoch sonlanma zamanını alır\n","        ep_end = time.time()\n","        # Epoch süresini hesaplar\n","        duration = ep_end - self.ep_start\n","        # Mevcut öğrenme oranını float olarak alır\n","        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n","        current_lr = lr\n","        # logs None ise boş dict kullanır, metrikleri alır\n","        logs = logs or {}\n","        acc = logs.get('accuracy', 0.0)\n","        v_acc = logs.get('val_accuracy', 0.0)\n","        loss = logs.get('loss', float('inf'))\n","        v_loss = logs.get('val_loss', float('inf'))\n","    \n","        if acc < self.threshold:  # Eğitim doğruluğu eşikten düşükse\n","            monitor = 'accuracy'\n","            if epoch == 0:\n","                pimprov = 0.0\n","            else:\n","                pimprov = (acc - self.highest_tracc) * 100 / max(self.highest_tracc, 1e-10)\n","            \n","            if acc > self.highest_tracc:\n","                self.highest_tracc = acc\n","                self.best_weights = self.model.get_weights()\n","                self.count = 0\n","                self.stop_count = 0\n","                if v_loss < self.lowest_vloss:\n","                    self.lowest_vloss = v_loss\n","                self.best_epoch = epoch + 1\n","            else:\n","                self.count += 1\n","                if self.count >= self.patience:\n","                    new_lr = float(lr * self.factor)  # float çarpım\n","                    self.model.optimizer.learning_rate.assign(new_lr)  # Öğrenme oranını günceller\n","                    self.count = 0\n","                    self.stop_count += 1\n","                    print(f\"Learning rate reduced to {new_lr}\")\n","                    lr = new_lr  # lr'yi güncelle\n","                    if v_loss < self.lowest_vloss:\n","                        self.lowest_vloss = v_loss\n","    \n","        else:  # Eğitim doğruluğu eşikten büyükse\n","            monitor = 'val_loss'\n","            if epoch == 0:\n","                pimprov = 0.0\n","            else:\n","                pimprov = (self.lowest_vloss - v_loss) * 100 / max(self.lowest_vloss, 1e-10)\n","            \n","            if v_loss < self.lowest_vloss:\n","                self.lowest_vloss = v_loss\n","                self.best_weights = self.model.get_weights()\n","                self.count = 0\n","                self.stop_count = 0\n","                self.best_epoch = epoch + 1\n","                if acc > self.highest_tracc:\n","                    self.highest_tracc = acc\n","            else:\n","                self.count += 1\n","                if self.count >= self.patience:\n","                    new_lr = float(lr * self.factor)  # float çarpım\n","                    self.model.optimizer.learning_rate.assign(new_lr)  # Öğrenme oranını günceller\n","                    self.count = 0\n","                    self.stop_count += 1\n","                    print(f\"Learning rate reduced to {new_lr}\")\n","                    lr = new_lr  # lr'yi güncelle\n","                if acc > self.highest_tracc:\n","                    self.highest_tracc = acc\n","    \n","        if self.stop_count >= self.stop_patience:\n","            msg = f'training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n","            print(msg)\n","            self.model.stop_training = True\n","    \n","        # Epoch sonuçlarını yazdırır, Epoch X/Y formatında\n","        msg = f'{epoch + 1}/{self.epochs:^7d}{loss:^10.4f}{acc:^9.3f}{v_loss:^9.4f}{v_acc:^9.3f}{current_lr:^9.6f}{lr:^9.6f}{monitor:^10s}{pimprov:^10.2f}{duration:^8.2f}'\n","        print(msg)"]},{"cell_type":"markdown","metadata":{"id":"2zwhoj3zGG61"},"source":["#### **Function to plot history of training**"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:14:49.911475Z","iopub.status.busy":"2025-02-24T13:14:49.911246Z","iopub.status.idle":"2025-02-24T13:14:49.927143Z","shell.execute_reply":"2025-02-24T13:14:49.926455Z","shell.execute_reply.started":"2025-02-24T13:14:49.911445Z"},"id":"pU3eAW5jGG62","trusted":true},"outputs":[],"source":["def plot_training(hist):\n","    '''\n","    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n","    '''\n","\n","    # Define needed variables\n","    tr_acc = hist.history['accuracy']\n","    tr_loss = hist.history['loss']\n","    val_acc = hist.history['val_accuracy']\n","    val_loss = hist.history['val_loss']\n","    index_loss = np.argmin(val_loss)\n","    val_lowest = val_loss[index_loss]\n","    index_acc = np.argmax(val_acc)\n","    acc_highest = val_acc[index_acc]\n","    Epochs = [i+1 for i in range(len(tr_acc))]\n","    loss_label = f'best epoch= {str(index_loss + 1)}'\n","    acc_label = f'best epoch= {str(index_acc + 1)}'\n","\n","    # Plot training history\n","    plt.figure(figsize= (20, 8))\n","    plt.style.use('fivethirtyeight')\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n","    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n","    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n","    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n","    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n","    plt.title('Training and Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    plt.tight_layout\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"pK6cgu7LGG63"},"source":["#### **Function to create Confusion Matrix**"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:14:51.565157Z","iopub.status.busy":"2025-02-24T13:14:51.564801Z","iopub.status.idle":"2025-02-24T13:14:51.570934Z","shell.execute_reply":"2025-02-24T13:14:51.570035Z","shell.execute_reply.started":"2025-02-24T13:14:51.565130Z"},"id":"_4mPYHnzGG64","trusted":true},"outputs":[],"source":["def plot_confusion_matrix(cm, classes, normalize= False, title= 'Confusion Matrix', cmap= plt.cm.Blues):\n","\t'''\n","\tThis function plot confusion matrix method from sklearn package.\n","\t'''\n","\n","\tplt.figure(figsize= (10, 10))\n","\tplt.imshow(cm, interpolation= 'nearest', cmap= cmap)\n","\tplt.title(title)\n","\tplt.colorbar()\n","\n","\ttick_marks = np.arange(len(classes))\n","\tplt.xticks(tick_marks, classes, rotation= 45)\n","\tplt.yticks(tick_marks, classes)\n","\n","\tif normalize:\n","\t\tcm = cm.astype('float') / cm.sum(axis= 1)[:, np.newaxis]\n","\t\tprint('Normalized Confusion Matrix')\n","\n","\telse:\n","\t\tprint('Confusion Matrix, Without Normalization')\n","\n","\tprint(cm)\n","\n","\tthresh = cm.max() / 2.\n","\tfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","\t\tplt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n","\n","\tplt.tight_layout()\n","\tplt.ylabel('True Label')\n","\tplt.xlabel('Predicted Label')"]},{"cell_type":"markdown","metadata":{"id":"57eDFl3oGG65"},"source":["# **Model Structure**"]},{"cell_type":"markdown","metadata":{"id":"2GHNMVrhGG65"},"source":["#### **Start Reading Dataset**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:14:54.809550Z","iopub.status.busy":"2025-02-24T13:14:54.809192Z","iopub.status.idle":"2025-02-24T13:15:11.659505Z","shell.execute_reply":"2025-02-24T13:15:11.658659Z","shell.execute_reply.started":"2025-02-24T13:14:54.809523Z"},"id":"FWfxfQEVabWS","outputId":"d8be6a8d-5b19-49f7-bfa1-09a96ff58286","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5113 validated image filenames belonging to 8 classes.\n","Found 639 validated image filenames belonging to 8 classes.\n","Found 640 validated image filenames belonging to 8 classes.\n"]}],"source":["data_dir = '/kaggle/input/odir5k-classification/datasets'\n","\n","\n","try:\n","    # Get splitted data\n","    train_df, valid_df, test_df = split_data(data_dir)\n","\n","    # Get Generators\n","    batch_size = 40\n","    train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)\n","\n","except:\n","    print('Invalid Input')"]},{"cell_type":"markdown","metadata":{},"source":["#### **Display Image Sample**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T11:45:31.818294Z","iopub.status.busy":"2025-02-24T11:45:31.818062Z","iopub.status.idle":"2025-02-24T11:45:36.530094Z","shell.execute_reply":"2025-02-24T11:45:36.529017Z","shell.execute_reply.started":"2025-02-24T11:45:31.818275Z"},"trusted":true},"outputs":[],"source":["show_images(train_gen)"]},{"cell_type":"markdown","metadata":{"id":"3wvOKjeRGG65"},"source":["#### **Generic Model Creation**"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:15:11.660655Z","iopub.status.busy":"2025-02-24T13:15:11.660299Z","iopub.status.idle":"2025-02-24T13:15:11.665260Z","shell.execute_reply":"2025-02-24T13:15:11.664124Z","shell.execute_reply.started":"2025-02-24T13:15:11.660631Z"},"trusted":true},"outputs":[],"source":["# Create Model Structure\n","img_size = (224, 224)\n","channels = 3\n","img_shape = (img_size[0], img_size[1], channels)\n","class_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:15:11.667120Z","iopub.status.busy":"2025-02-24T13:15:11.666805Z","iopub.status.idle":"2025-02-24T13:15:11.725485Z","shell.execute_reply":"2025-02-24T13:15:11.724660Z","shell.execute_reply.started":"2025-02-24T13:15:11.667089Z"},"trusted":true},"outputs":[],"source":["# set callback parameters\n","\n","batch_size = 40   # set batch size for training\n","epochs = 30   # number of all epochs in training\n","patience = 5   #number of epochs to wait to adjust lr if monitored value does not improve\n","stop_patience = 3   # number of epochs to wait before stopping training if monitored value does not improve\n","threshold = 0.9   # if train accuracy is < threshold adjust monitor accuracy, else monitor validation loss\n","factor = 0.5   # factor to reduce lr by\n","ask_epoch = 5   # number of epochs to run before asking if you want to halt training\n","batches = int(np.ceil(len(train_gen.labels) / batch_size))    # number of training batch to run per epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:11:38.987179Z","iopub.status.busy":"2025-02-22T12:11:38.986931Z","iopub.status.idle":"2025-02-22T12:11:46.740789Z","shell.execute_reply":"2025-02-22T12:11:46.739822Z","shell.execute_reply.started":"2025-02-22T12:11:38.987155Z"},"id":"kDT4CV15abWT","outputId":"365637a8-7535-4ac4-90ea-700f6eb5769e","trusted":true},"outputs":[],"source":["# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n","\n","# we will use efficientnetb3 from EfficientNet family.\n","base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n","\n","model = Sequential([\n","    base_model,\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(256, kernel_regularizer= regularizers.l2(0.016), activity_regularizer= regularizers.l1(0.006),\n","                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n","    Dropout(rate= 0.45, seed= 123),\n","    Dense(class_count, activation= 'softmax')\n","])\n","\n","model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:11:46.754026Z","iopub.status.busy":"2025-02-22T12:11:46.753781Z","iopub.status.idle":"2025-02-22T12:15:37.342371Z","shell.execute_reply":"2025-02-22T12:15:37.341321Z","shell.execute_reply.started":"2025-02-22T12:11:46.754002Z"},"trusted":true},"outputs":[],"source":["callbacks = [MyCallback(model= model, patience= patience, stop_patience= stop_patience, threshold= threshold,\n","            factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]\n","\n","#train model\n","history = model.fit(x= train_gen, epochs= epochs, verbose= 0, callbacks= callbacks,\n","                    validation_data= valid_gen, validation_steps= None, shuffle= False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:15:37.344484Z","iopub.status.busy":"2025-02-22T12:15:37.344032Z","iopub.status.idle":"2025-02-22T12:15:37.831571Z","shell.execute_reply":"2025-02-22T12:15:37.830570Z","shell.execute_reply.started":"2025-02-22T12:15:37.344445Z"},"trusted":true},"outputs":[],"source":["# display model performance\n","plot_training(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:15:37.833119Z","iopub.status.busy":"2025-02-22T12:15:37.832835Z","iopub.status.idle":"2025-02-22T12:15:47.225351Z","shell.execute_reply":"2025-02-22T12:15:47.224461Z","shell.execute_reply.started":"2025-02-22T12:15:37.833092Z"},"trusted":true},"outputs":[],"source":["# evaluate model\n","ts_length = len(test_df)\n","test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","test_steps = ts_length // test_batch_size\n","\n","train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n","valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n","test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n","\n","print(\"Train Loss: \", train_score[0])\n","print(\"Train Accuracy: \", train_score[1])\n","print('-' * 20)\n","print(\"Validation Loss: \", valid_score[0])\n","print(\"Validation Accuracy: \", valid_score[1])\n","print('-' * 20)\n","print(\"Test Loss: \", test_score[0])\n","print(\"Test Accuracy: \", test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"execution_failed":"2025-02-22T12:51:31.778Z","iopub.execute_input":"2025-02-22T12:48:13.387366Z","iopub.status.busy":"2025-02-22T12:48:13.386451Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","# ROC ve AUC çizimi için fonksiyon\n","def plot_roc_auc(y_test, y_pred_probs, class_count):\n","    if len(y_test.shape) == 1:\n","        y_true_onehot = tf.keras.utils.to_categorical(y_test, num_classes=class_count)\n","    else:\n","        y_true_onehot = y_test\n","    \n","    fpr = {}\n","    tpr = {}\n","    roc_auc = {}\n","    for i in range(class_count):\n","        fpr[i], tpr[i], _ = roc_curve(y_true_onehot[:, i], y_pred_probs[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","    \n","    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_onehot.ravel(), y_pred_probs.ravel())\n","    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","    \n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(class_count)]))\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for i in range(class_count):\n","        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","    mean_tpr /= class_count\n","    fpr[\"macro\"] = all_fpr\n","    tpr[\"macro\"] = mean_tpr\n","    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","    \n","    plt.figure(figsize=(10, 8))\n","    for i in range(class_count):\n","        plt.plot(fpr[i], tpr[i], label=f'Sınıf {i} (AUC = {roc_auc[i]:.2f})')\n","    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Mikro-ortalama (AUC = {roc_auc[\"micro\"]:.2f})', linestyle='--')\n","    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'Makro-ortalama (AUC = {roc_auc[\"macro\"]:.2f})', linestyle='--')\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Yanlış Pozitif Oranı')\n","    plt.ylabel('Doğru Pozitif Oranı')\n","    plt.title('EfficientNetB3 ROC Eğrisi')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","# Batch bazında tahmin yapma\n","preds = []\n","y_test = []\n","steps = len(test_gen)  # Test setindeki batch sayısı\n","for i, (batch_x, batch_y) in enumerate(test_gen):\n","    if i >= steps:\n","        break\n","    batch_preds = model.predict(batch_x, verbose=0)  # Her batch için tahmin\n","    preds.append(batch_preds)\n","    y_test.append(batch_y)\n","\n","preds = np.concatenate(preds, axis=0)\n","y_test = np.concatenate(y_test, axis=0)\n","\n","y_pred = np.argmax(preds, axis=1)\n","print(\"Tahmin edilen sınıf indeksleri:\", y_pred)\n","\n","# ROC ve AUC çizimi\n","plot_roc_auc(y_test, preds, class_count=len(list(train_gen.class_indices.keys())))  # Sınıf sayınızı buraya girin"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:15:57.001664Z","iopub.status.busy":"2025-02-22T12:15:57.001383Z","iopub.status.idle":"2025-02-22T12:15:57.639054Z","shell.execute_reply":"2025-02-22T12:15:57.638115Z","shell.execute_reply.started":"2025-02-22T12:15:57.001636Z"},"trusted":true},"outputs":[],"source":["g_dict = test_gen.class_indices\n","classes = list(g_dict.keys())\n","\n","# Confusion matrix\n","cm = confusion_matrix(test_gen.classes, y_pred)\n","plot_confusion_matrix(cm= cm, classes= classes, title = 'Confusion Matrix')\n","\n","# Classification report\n","print(classification_report(test_gen.classes, y_pred, target_names= classes))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:15:57.640668Z","iopub.status.busy":"2025-02-22T12:15:57.640297Z","iopub.status.idle":"2025-02-22T12:16:02.189515Z","shell.execute_reply":"2025-02-22T12:16:02.188222Z","shell.execute_reply.started":"2025-02-22T12:15:57.640628Z"},"trusted":true},"outputs":[],"source":["# DenseNet121\n","densenet_model = tf.keras.applications.densenet.DenseNet121(weights='imagenet', include_top=True, input_shape= img_shape, pooling = 'max')\n","\n","model = Sequential([\n","    densenet_model,\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(256, kernel_regularizer= regularizers.l2(0.016), activity_regularizer= regularizers.l1(0.006),\n","                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n","    Dropout(rate= 0.45, seed= 123),\n","    Dense(class_count, activation= 'softmax')\n","])\n","\n","model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:16:02.191332Z","iopub.status.busy":"2025-02-22T12:16:02.190975Z","iopub.status.idle":"2025-02-22T12:19:11.123791Z","shell.execute_reply":"2025-02-22T12:19:11.122762Z","shell.execute_reply.started":"2025-02-22T12:16:02.191298Z"},"trusted":true},"outputs":[],"source":["callbacks = [MyCallback(model= model, patience= patience, stop_patience= stop_patience, threshold= threshold,\n","            factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]\n","\n","#train model\n","history = model.fit(x= train_gen, epochs= epochs, verbose= 0, callbacks= callbacks,\n","                    validation_data= valid_gen, validation_steps= None, shuffle= False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:19:11.125637Z","iopub.status.busy":"2025-02-22T12:19:11.125340Z","iopub.status.idle":"2025-02-22T12:19:11.652069Z","shell.execute_reply":"2025-02-22T12:19:11.650936Z","shell.execute_reply.started":"2025-02-22T12:19:11.125583Z"},"trusted":true},"outputs":[],"source":["# display model performance\n","plot_training(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:19:11.653970Z","iopub.status.busy":"2025-02-22T12:19:11.653582Z","iopub.status.idle":"2025-02-22T12:19:20.354508Z","shell.execute_reply":"2025-02-22T12:19:20.353627Z","shell.execute_reply.started":"2025-02-22T12:19:11.653934Z"},"trusted":true},"outputs":[],"source":["# evaluate model\n","ts_length = len(test_df)\n","test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","test_steps = ts_length // test_batch_size\n","\n","train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n","valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n","test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n","\n","print(\"Train Loss: \", train_score[0])\n","print(\"Train Accuracy: \", train_score[1])\n","print('-' * 20)\n","print(\"Validation Loss: \", valid_score[0])\n","print(\"Validation Accuracy: \", valid_score[1])\n","print('-' * 20)\n","print(\"Test Loss: \", test_score[0])\n","print(\"Test Accuracy: \", test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:19:24.932731Z","iopub.status.busy":"2025-02-22T12:19:24.932185Z","iopub.status.idle":"2025-02-22T12:19:34.940223Z","shell.execute_reply":"2025-02-22T12:19:34.939328Z","shell.execute_reply.started":"2025-02-22T12:19:24.932688Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","# ROC ve AUC çizimi için fonksiyon\n","def plot_roc_auc(y_test, y_pred_probs, class_count):\n","    if len(y_test.shape) == 1:\n","        y_true_onehot = tf.keras.utils.to_categorical(y_test, num_classes=class_count)\n","    else:\n","        y_true_onehot = y_test\n","    \n","    fpr = {}\n","    tpr = {}\n","    roc_auc = {}\n","    for i in range(class_count):\n","        fpr[i], tpr[i], _ = roc_curve(y_true_onehot[:, i], y_pred_probs[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","    \n","    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_onehot.ravel(), y_pred_probs.ravel())\n","    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","    \n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(class_count)]))\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for i in range(class_count):\n","        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","    mean_tpr /= class_count\n","    fpr[\"macro\"] = all_fpr\n","    tpr[\"macro\"] = mean_tpr\n","    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","    \n","    plt.figure(figsize=(10, 8))\n","    for i in range(class_count):\n","        plt.plot(fpr[i], tpr[i], label=f'Sınıf {i} (AUC = {roc_auc[i]:.2f})')\n","    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Mikro-ortalama (AUC = {roc_auc[\"micro\"]:.2f})', linestyle='--')\n","    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'Makro-ortalama (AUC = {roc_auc[\"macro\"]:.2f})', linestyle='--')\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Yanlış Pozitif Oranı')\n","    plt.ylabel('Doğru Pozitif Oranı')\n","    plt.title('DenseNet121 ROC Eğrisi')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","# Batch bazında tahmin yapma\n","preds = []\n","y_test = []\n","steps = len(test_gen)  # Test setindeki batch sayısı\n","for i, (batch_x, batch_y) in enumerate(test_gen):\n","    if i >= steps:\n","        break\n","    batch_preds = model.predict(batch_x, verbose=0)  # Her batch için tahmin\n","    preds.append(batch_preds)\n","    y_test.append(batch_y)\n","\n","preds = np.concatenate(preds, axis=0)\n","y_test = np.concatenate(y_test, axis=0)\n","\n","y_pred = np.argmax(preds, axis=1)\n","print(\"Tahmin edilen sınıf indeksleri:\", y_pred)\n","\n","# ROC ve AUC çizimi\n","plot_roc_auc(y_test, preds, class_count=len(list(train_gen.class_indices.keys())))  # Sınıf sayınızı buraya girin"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:19:34.941861Z","iopub.status.busy":"2025-02-22T12:19:34.941492Z","iopub.status.idle":"2025-02-22T12:19:35.573160Z","shell.execute_reply":"2025-02-22T12:19:35.572178Z","shell.execute_reply.started":"2025-02-22T12:19:34.941826Z"},"trusted":true},"outputs":[],"source":["g_dict = test_gen.class_indices\n","classes = list(g_dict.keys())\n","\n","# Confusion matrix\n","cm = confusion_matrix(test_gen.classes, y_pred)\n","plot_confusion_matrix(cm= cm, classes= classes, title = 'Confusion Matrix')\n","\n","# Classification report\n","print(classification_report(test_gen.classes, y_pred, target_names= classes))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:19:35.574634Z","iopub.status.busy":"2025-02-22T12:19:35.574324Z","iopub.status.idle":"2025-02-22T12:19:38.287407Z","shell.execute_reply":"2025-02-22T12:19:38.286522Z","shell.execute_reply.started":"2025-02-22T12:19:35.574577Z"},"trusted":true},"outputs":[],"source":["# ResNet50\n","resnet_model = tf.keras.applications.resnet.ResNet50(weights='imagenet', include_top=True, input_shape= img_shape, pooling = 'max')\n","\n","model = Sequential([\n","    resnet_model,\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(256, kernel_regularizer= regularizers.l2(0.016), activity_regularizer= regularizers.l1(0.006),\n","                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n","    Dropout(rate= 0.45, seed= 123),\n","    Dense(class_count, activation= 'softmax')\n","])\n","\n","model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:19:38.289014Z","iopub.status.busy":"2025-02-22T12:19:38.288721Z","iopub.status.idle":"2025-02-22T12:22:18.217450Z","shell.execute_reply":"2025-02-22T12:22:18.216436Z","shell.execute_reply.started":"2025-02-22T12:19:38.288986Z"},"id":"7abvdv7mGG66","trusted":true},"outputs":[],"source":["callbacks = [MyCallback(model= model, patience= patience, stop_patience= stop_patience, threshold= threshold,\n","            factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]\n","\n","#training\n","history = model.fit(x= train_gen, epochs= epochs, verbose= 0, callbacks= callbacks,\n","                    validation_data= valid_gen, validation_steps= None, shuffle= False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:22:18.219091Z","iopub.status.busy":"2025-02-22T12:22:18.218828Z","iopub.status.idle":"2025-02-22T12:22:18.642381Z","shell.execute_reply":"2025-02-22T12:22:18.641466Z","shell.execute_reply.started":"2025-02-22T12:22:18.219066Z"},"trusted":true},"outputs":[],"source":["# display model performance\n","plot_training(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:22:18.643928Z","iopub.status.busy":"2025-02-22T12:22:18.643671Z","iopub.status.idle":"2025-02-22T12:22:26.166093Z","shell.execute_reply":"2025-02-22T12:22:26.165023Z","shell.execute_reply.started":"2025-02-22T12:22:18.643904Z"},"trusted":true},"outputs":[],"source":["# evaluate model\n","ts_length = len(test_df)\n","test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","test_steps = ts_length // test_batch_size\n","\n","train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n","valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n","test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n","\n","print(\"Train Loss: \", train_score[0])\n","print(\"Train Accuracy: \", train_score[1])\n","print('-' * 20)\n","print(\"Validation Loss: \", valid_score[0])\n","print(\"Validation Accuracy: \", valid_score[1])\n","print('-' * 20)\n","print(\"Test Loss: \", test_score[0])\n","print(\"Test Accuracy: \", test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:22:29.930998Z","iopub.status.busy":"2025-02-22T12:22:29.930714Z","iopub.status.idle":"2025-02-22T12:22:37.708805Z","shell.execute_reply":"2025-02-22T12:22:37.707799Z","shell.execute_reply.started":"2025-02-22T12:22:29.930964Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","# ROC ve AUC çizimi için fonksiyon\n","def plot_roc_auc(y_test, y_pred_probs, class_count):\n","    if len(y_test.shape) == 1:\n","        y_true_onehot = tf.keras.utils.to_categorical(y_test, num_classes=class_count)\n","    else:\n","        y_true_onehot = y_test\n","    \n","    fpr = {}\n","    tpr = {}\n","    roc_auc = {}\n","    for i in range(class_count):\n","        fpr[i], tpr[i], _ = roc_curve(y_true_onehot[:, i], y_pred_probs[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","    \n","    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_onehot.ravel(), y_pred_probs.ravel())\n","    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","    \n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(class_count)]))\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for i in range(class_count):\n","        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","    mean_tpr /= class_count\n","    fpr[\"macro\"] = all_fpr\n","    tpr[\"macro\"] = mean_tpr\n","    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","    \n","    plt.figure(figsize=(10, 8))\n","    for i in range(class_count):\n","        plt.plot(fpr[i], tpr[i], label=f'Sınıf {i} (AUC = {roc_auc[i]:.2f})')\n","    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Mikro-ortalama (AUC = {roc_auc[\"micro\"]:.2f})', linestyle='--')\n","    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'Makro-ortalama (AUC = {roc_auc[\"macro\"]:.2f})', linestyle='--')\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Yanlış Pozitif Oranı')\n","    plt.ylabel('Doğru Pozitif Oranı')\n","    plt.title('ResNet50 ROC Eğrisi')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","# Batch bazında tahmin yapma\n","preds = []\n","y_test = []\n","steps = len(test_gen)  # Test setindeki batch sayısı\n","for i, (batch_x, batch_y) in enumerate(test_gen):\n","    if i >= steps:\n","        break\n","    batch_preds = model.predict(batch_x, verbose=0)  # Her batch için tahmin\n","    preds.append(batch_preds)\n","    y_test.append(batch_y)\n","\n","preds = np.concatenate(preds, axis=0)\n","y_test = np.concatenate(y_test, axis=0)\n","\n","y_pred = np.argmax(preds, axis=1)\n","print(\"Tahmin edilen sınıf indeksleri:\", y_pred)\n","\n","# ROC ve AUC çizimi\n","plot_roc_auc(y_test, preds, class_count=len(list(train_gen.class_indices.keys())))  # Sınıf sayınızı buraya girin"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:22:37.710253Z","iopub.status.busy":"2025-02-22T12:22:37.709973Z","iopub.status.idle":"2025-02-22T12:22:40.097888Z","shell.execute_reply":"2025-02-22T12:22:40.096909Z","shell.execute_reply.started":"2025-02-22T12:22:37.710227Z"},"trusted":true},"outputs":[],"source":["g_dict = test_gen.class_indices\n","classes = list(g_dict.keys())\n","\n","# Confusion matrix\n","cm = confusion_matrix(test_gen.classes, y_pred)\n","plot_confusion_matrix(cm= cm, classes= classes, title = 'Confusion Matrix')\n","\n","# Classification report\n","print(classification_report(test_gen.classes, y_pred, target_names= classes))"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:17:46.962086Z","iopub.status.busy":"2025-02-24T13:17:46.961755Z","iopub.status.idle":"2025-02-24T13:17:47.705794Z","shell.execute_reply":"2025-02-24T13:17:47.705126Z","shell.execute_reply.started":"2025-02-24T13:17:46.962059Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ mobilenetv2_1.00_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,538,984</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">256,256</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ mobilenetv2_1.00_224 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │       \u001b[38;5;34m3,538,984\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │           \u001b[38;5;34m4,000\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m256,256\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │           \u001b[38;5;34m2,056\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,801,296</span> (14.50 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,801,296\u001b[0m (14.50 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,765,184</span> (14.36 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,765,184\u001b[0m (14.36 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,112</span> (141.06 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m36,112\u001b[0m (141.06 KB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["# MobileNetV2\n","mobilenet_model = tf.keras.applications.mobilenet_v2.MobileNetV2(weights='imagenet', include_top=True, input_shape= img_shape, pooling = 'max')\n","\n","model = Sequential([\n","    mobilenet_model,\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(256, kernel_regularizer= regularizers.l2(0.016), activity_regularizer= regularizers.l1(0.006),\n","                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n","    Dropout(rate= 0.45, seed= 123),\n","    Dense(class_count, activation= 'softmax')\n","])\n","\n","model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:17:58.107856Z","iopub.status.busy":"2025-02-24T13:17:58.107550Z","iopub.status.idle":"2025-02-24T13:21:52.243182Z","shell.execute_reply":"2025-02-24T13:21:52.241489Z","shell.execute_reply.started":"2025-02-24T13:17:58.107833Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n","Training started. Initial learning rate: 0.0010000000474974513\n","Epoch 1/40 started\n","1/  40     3.8152    0.431   2.2256    0.449  0.001000 0.001000  accuracy    0.00    98.92  \n","Epoch 2/40 started\n","2/  40     2.0520    0.449   1.9651    0.449  0.001000 0.001000  accuracy    4.26    19.59  \n","Epoch 3/40 started\n","3/  40     1.9264    0.449   1.8923    0.449  0.001000 0.001000  accuracy    0.00    19.45  \n","Epoch 4/40 started\n","4/  40     1.8643    0.449   1.8368    0.449  0.001000 0.001000  accuracy    0.00    19.62  \n","Epoch 5/40 started\n","5/  40     1.8124    0.449   1.7884    0.449  0.001000 0.001000  accuracy    0.00    19.12  \n","Epoch 6/40 started\n","6/  40     1.7683    0.449   1.7487    0.449  0.001000 0.001000  accuracy    0.00    18.58  \n","Epoch 7/40 started\n","Learning rate reduced to 0.00050000002374872578  -   accuracy=  44.944   -   loss:  1.73182 \n","7/  40     1.7318    0.449   1.7152    0.449  0.001000 0.000500  accuracy    0.00    18.89  \n","Epoch 8/40 started\n","8/  40     1.7076    0.449   1.6999    0.449  0.000500 0.000500  accuracy    0.00    18.80  \n","Epoch 9/40 started\n","                    processing batch 1 of 128  -   accuracy=  45.000   -   loss:  1.73447 \r"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-4e9585878961>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m history = model.fit(x= train_gen, epochs= epochs, verbose= 0, callbacks= callbacks,\n\u001b[0m\u001b[1;32m      6\u001b[0m                     validation_data= valid_gen, validation_steps= None, shuffle= False)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["callbacks = [MyCallback(model= model, patience= patience, stop_patience= stop_patience, threshold= threshold,\n","            factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]\n","\n","#training\n","history = model.fit(x= train_gen, epochs= epochs, verbose= 0, callbacks= callbacks,\n","                    validation_data= valid_gen, validation_steps= None, shuffle= False)"]},{"cell_type":"markdown","metadata":{"id":"dNKq6ebOGG67"},"source":["#### **Display model performance**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:23:55.867697Z","iopub.status.busy":"2025-02-22T12:23:55.867348Z","iopub.status.idle":"2025-02-22T12:23:56.369507Z","shell.execute_reply":"2025-02-22T12:23:56.368515Z","shell.execute_reply.started":"2025-02-22T12:23:55.867656Z"},"id":"L0Bj0Sp_GG68","outputId":"663963ec-ea21-4272-8dda-a16c5f5e2ce5","trusted":true},"outputs":[],"source":["plot_training(history)"]},{"cell_type":"markdown","metadata":{"id":"MySXhfAJGG68"},"source":["# **Evaluate model**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:23:56.371115Z","iopub.status.busy":"2025-02-22T12:23:56.370832Z","iopub.status.idle":"2025-02-22T12:24:02.144106Z","shell.execute_reply":"2025-02-22T12:24:02.143072Z","shell.execute_reply.started":"2025-02-22T12:23:56.371088Z"},"id":"wSKDkyXXGG68","outputId":"b521980b-a33b-421b-8cdf-4d92fb0f304a","trusted":true},"outputs":[],"source":["ts_length = len(test_df)\n","test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","test_steps = ts_length // test_batch_size\n","\n","train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n","valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n","test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n","\n","print(\"Train Loss: \", train_score[0])\n","print(\"Train Accuracy: \", train_score[1])\n","print('-' * 20)\n","print(\"Validation Loss: \", valid_score[0])\n","print(\"Validation Accuracy: \", valid_score[1])\n","print('-' * 20)\n","print(\"Test Loss: \", test_score[0])\n","print(\"Test Accuracy: \", test_score[1])"]},{"cell_type":"markdown","metadata":{"id":"4l-DABtFGG68"},"source":["# **Get Predictions**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:24:05.547757Z","iopub.status.busy":"2025-02-22T12:24:05.547418Z","iopub.status.idle":"2025-02-22T12:24:11.203398Z","shell.execute_reply":"2025-02-22T12:24:11.202521Z","shell.execute_reply.started":"2025-02-22T12:24:05.547721Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","# ROC ve AUC çizimi için fonksiyon\n","def plot_roc_auc(y_test, y_pred_probs, class_count):\n","    if len(y_test.shape) == 1:\n","        y_true_onehot = tf.keras.utils.to_categorical(y_test, num_classes=class_count)\n","    else:\n","        y_true_onehot = y_test\n","    \n","    fpr = {}\n","    tpr = {}\n","    roc_auc = {}\n","    for i in range(class_count):\n","        fpr[i], tpr[i], _ = roc_curve(y_true_onehot[:, i], y_pred_probs[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","    \n","    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_onehot.ravel(), y_pred_probs.ravel())\n","    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","    \n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(class_count)]))\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for i in range(class_count):\n","        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","    mean_tpr /= class_count\n","    fpr[\"macro\"] = all_fpr\n","    tpr[\"macro\"] = mean_tpr\n","    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","    \n","    plt.figure(figsize=(10, 8))\n","    for i in range(class_count):\n","        plt.plot(fpr[i], tpr[i], label=f'Sınıf {i} (AUC = {roc_auc[i]:.2f})')\n","    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Mikro-ortalama (AUC = {roc_auc[\"micro\"]:.2f})', linestyle='--')\n","    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'Makro-ortalama (AUC = {roc_auc[\"macro\"]:.2f})', linestyle='--')\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Yanlış Pozitif Oranı')\n","    plt.ylabel('Doğru Pozitif Oranı')\n","    plt.title('MobileNetV2 ROC Eğrisi')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","# Batch bazında tahmin yapma\n","preds = []\n","y_test = []\n","steps = len(test_gen)  # Test setindeki batch sayısı\n","for i, (batch_x, batch_y) in enumerate(test_gen):\n","    if i >= steps:\n","        break\n","    batch_preds = model.predict(batch_x, verbose=0)  # Her batch için tahmin\n","    preds.append(batch_preds)\n","    y_test.append(batch_y)\n","\n","preds = np.concatenate(preds, axis=0)\n","y_test = np.concatenate(y_test, axis=0)\n","\n","y_pred = np.argmax(preds, axis=1)\n","print(\"Tahmin edilen sınıf indeksleri:\", y_pred)\n","\n","# ROC ve AUC çizimi\n","plot_roc_auc(y_test, preds, class_count=len(list(train_gen.class_indices.keys())))  # Sınıf sayınızı buraya girin"]},{"cell_type":"markdown","metadata":{"id":"aJscUTF6GG69"},"source":["#### **Confusion Matrics and Classification Report**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:24:11.212090Z","iopub.status.busy":"2025-02-22T12:24:11.211512Z","iopub.status.idle":"2025-02-22T12:24:11.791841Z","shell.execute_reply":"2025-02-22T12:24:11.790850Z","shell.execute_reply.started":"2025-02-22T12:24:11.212061Z"},"id":"tQR-UlD6GG69","outputId":"09ac1d97-2053-4633-e066-ca11540a2e27","trusted":true},"outputs":[],"source":["g_dict = test_gen.class_indices\n","classes = list(g_dict.keys())\n","\n","# Confusion matrix\n","cm = confusion_matrix(test_gen.classes, y_pred)\n","plot_confusion_matrix(cm= cm, classes= classes, title = 'Confusion Matrix')\n","\n","# Classification report\n","print(classification_report(test_gen.classes, y_pred, target_names= classes))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:24:11.793345Z","iopub.status.busy":"2025-02-22T12:24:11.793098Z","iopub.status.idle":"2025-02-22T12:24:21.769946Z","shell.execute_reply":"2025-02-22T12:24:21.769086Z","shell.execute_reply.started":"2025-02-22T12:24:11.793322Z"},"trusted":true},"outputs":[],"source":["!pip install vit-keras tensorflow-addons\n","from vit_keras import vit"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:24:21.772472Z","iopub.status.busy":"2025-02-22T12:24:21.771544Z","iopub.status.idle":"2025-02-22T12:24:28.474086Z","shell.execute_reply":"2025-02-22T12:24:28.473098Z","shell.execute_reply.started":"2025-02-22T12:24:21.772426Z"},"trusted":true},"outputs":[],"source":["# ViT modelini yükleme\n","base_model = vit.vit_b16(\n","    image_size=224,        # Girdi boyutu\n","    pretrained=True,       # ImageNet ağırlıkları\n","    include_top=False,     # Son sınıflandırma katmanını hariç tut\n","    pretrained_top=False\n",")\n","\n","# ViT modelinin çıktısı zaten [CLS] token veya havuzlanmış temsil (batch_size, 768)\n","# Bu nedenle, cls_token çıkarmaya gerek yok; base_model.output'u doğrudan kullanabiliriz\n","\n","# Sequential model oluşturma\n","model = Sequential([\n","    base_model,\n","    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n","    Dense(256, kernel_regularizer=regularizers.l2(0.016), \n","          activity_regularizer=regularizers.l1(0.006),\n","          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n","    Dropout(rate=0.45, seed=123),\n","    Dense(class_count, activation='softmax')\n","])\n","\n","# Modeli derleme\n","model.compile(optimizer=Adamax(learning_rate=0.001), \n","              loss='categorical_crossentropy', \n","              metrics=['accuracy'])\n","\n","# Model özetini yazdırma\n","model.summary()\n","\n","# Create a dummy input\n","dummy_input = tf.random.normal((1, 224, 224, 3))\n","\n","# Get the output\n","output = base_model(dummy_input)\n","\n","print(output.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:24:28.476168Z","iopub.status.busy":"2025-02-22T12:24:28.475376Z","iopub.status.idle":"2025-02-22T12:33:15.113969Z","shell.execute_reply":"2025-02-22T12:33:15.113174Z","shell.execute_reply.started":"2025-02-22T12:24:28.476136Z"},"trusted":true},"outputs":[],"source":["callbacks = [MyCallback(model= model, patience= patience, stop_patience= stop_patience, threshold= threshold,\n","            factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]\n","\n","#training\n","history = model.fit(x= train_gen, epochs= epochs, verbose= 0, callbacks= callbacks,\n","                    validation_data= valid_gen, validation_steps= None, shuffle= False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:33:15.115479Z","iopub.status.busy":"2025-02-22T12:33:15.115155Z","iopub.status.idle":"2025-02-22T12:33:15.602665Z","shell.execute_reply":"2025-02-22T12:33:15.601788Z","shell.execute_reply.started":"2025-02-22T12:33:15.115439Z"},"trusted":true},"outputs":[],"source":["plot_training(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:33:15.604670Z","iopub.status.busy":"2025-02-22T12:33:15.603979Z","iopub.status.idle":"2025-02-22T12:33:36.062879Z","shell.execute_reply":"2025-02-22T12:33:36.061927Z","shell.execute_reply.started":"2025-02-22T12:33:15.604632Z"},"trusted":true},"outputs":[],"source":["ts_length = len(test_df)\n","test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","test_steps = ts_length // test_batch_size\n","\n","train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n","valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n","test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n","\n","print(\"Train Loss: \", train_score[0])\n","print(\"Train Accuracy: \", train_score[1])\n","print('-' * 20)\n","print(\"Validation Loss: \", valid_score[0])\n","print(\"Validation Accuracy: \", valid_score[1])\n","print('-' * 20)\n","print(\"Test Loss: \", test_score[0])\n","print(\"Test Accuracy: \", test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:33:48.869910Z","iopub.status.busy":"2025-02-22T12:33:48.869553Z","iopub.status.idle":"2025-02-22T12:34:04.289734Z","shell.execute_reply":"2025-02-22T12:34:04.288715Z","shell.execute_reply.started":"2025-02-22T12:33:48.869881Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","# ROC ve AUC çizimi için fonksiyon\n","def plot_roc_auc(y_test, y_pred_probs, class_count):\n","    if len(y_test.shape) == 1:\n","        y_true_onehot = tf.keras.utils.to_categorical(y_test, num_classes=class_count)\n","    else:\n","        y_true_onehot = y_test\n","    \n","    fpr = {}\n","    tpr = {}\n","    roc_auc = {}\n","    for i in range(class_count):\n","        fpr[i], tpr[i], _ = roc_curve(y_true_onehot[:, i], y_pred_probs[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","    \n","    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_onehot.ravel(), y_pred_probs.ravel())\n","    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","    \n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(class_count)]))\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for i in range(class_count):\n","        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","    mean_tpr /= class_count\n","    fpr[\"macro\"] = all_fpr\n","    tpr[\"macro\"] = mean_tpr\n","    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","    \n","    plt.figure(figsize=(10, 8))\n","    for i in range(class_count):\n","        plt.plot(fpr[i], tpr[i], label=f'Sınıf {i} (AUC = {roc_auc[i]:.2f})')\n","    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Mikro-ortalama (AUC = {roc_auc[\"micro\"]:.2f})', linestyle='--')\n","    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'Makro-ortalama (AUC = {roc_auc[\"macro\"]:.2f})', linestyle='--')\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Yanlış Pozitif Oranı')\n","    plt.ylabel('Doğru Pozitif Oranı')\n","    plt.title('VitB16 ROC Eğrisi')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","# Batch bazında tahmin yapma\n","preds = []\n","y_test = []\n","steps = len(test_gen)  # Test setindeki batch sayısı\n","for i, (batch_x, batch_y) in enumerate(test_gen):\n","    if i >= steps:\n","        break\n","    batch_preds = model.predict(batch_x, verbose=0)  # Her batch için tahmin\n","    preds.append(batch_preds)\n","    y_test.append(batch_y)\n","\n","preds = np.concatenate(preds, axis=0)\n","y_test = np.concatenate(y_test, axis=0)\n","\n","y_pred = np.argmax(preds, axis=1)\n","print(\"Tahmin edilen sınıf indeksleri:\", y_pred)\n","\n","# ROC ve AUC çizimi\n","plot_roc_auc(y_test, preds, class_count=len(list(train_gen.class_indices.keys())))  # Sınıf sayınızı buraya girin"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-22T12:34:04.291171Z","iopub.status.busy":"2025-02-22T12:34:04.290890Z","iopub.status.idle":"2025-02-22T12:34:04.928039Z","shell.execute_reply":"2025-02-22T12:34:04.927135Z","shell.execute_reply.started":"2025-02-22T12:34:04.291144Z"},"trusted":true},"outputs":[],"source":["g_dict = test_gen.class_indices\n","classes = list(g_dict.keys())\n","\n","# Confusion matrix\n","cm = confusion_matrix(test_gen.classes, y_pred)\n","plot_confusion_matrix(cm= cm, classes= classes, title = 'Confusion Matrix')\n","\n","# Classification report\n","print(classification_report(test_gen.classes, y_pred, target_names= classes))"]},{"cell_type":"markdown","metadata":{},"source":["# CNN-Vision Transformer (ConvIT)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:15:11.726618Z","iopub.status.busy":"2025-02-24T13:15:11.726364Z","iopub.status.idle":"2025-02-24T13:15:14.328080Z","shell.execute_reply":"2025-02-24T13:15:14.327130Z","shell.execute_reply.started":"2025-02-24T13:15:11.726597Z"},"trusted":true},"outputs":[],"source":["# Örnek parametreler\n","#img_shape = (224, 224, 3)  # Giriş şekli\n","#class_count = 10           # Sınıf sayısı (verinize göre ayarlayın)\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, LayerNormalization, MultiHeadAttention, Layer, Input, Reshape, Lambda\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.optimizers import Adamax\n","\n","# CNN katmanları ile özellik çıkarımı\n","inputs = Input(shape=img_shape)\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","x = MaxPooling2D((2, 2))(x)\n","x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = MaxPooling2D((2, 2))(x)\n","x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","cnn_output = MaxPooling2D((2, 2))(x)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:15:14.329572Z","iopub.status.busy":"2025-02-24T13:15:14.329268Z","iopub.status.idle":"2025-02-24T13:15:14.334714Z","shell.execute_reply":"2025-02-24T13:15:14.333681Z","shell.execute_reply.started":"2025-02-24T13:15:14.329538Z"},"trusted":true},"outputs":[],"source":["# Özellik haritalarını patch'lere dönüştürme\n","sequence_length = 28 * 28  # 224 / (2^3) = 28, ama padding ile 26 olabilir, doğrulayın\n","embedding_dim = 128        # Her patch'in gömme boyutu (kanal sayısı)\n","patch_embeddings = Reshape((sequence_length, embedding_dim))(cnn_output)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:15:16.564693Z","iopub.status.busy":"2025-02-24T13:15:16.564303Z","iopub.status.idle":"2025-02-24T13:15:16.600096Z","shell.execute_reply":"2025-02-24T13:15:16.599230Z","shell.execute_reply.started":"2025-02-24T13:15:16.564663Z"},"trusted":true},"outputs":[],"source":["# [CLS] token için Dense katmanını fonksiyonun dışında tanımla\n","cls_dense_layer = tf.keras.layers.Dense(embedding_dim, activation='relu')\n","\n","def add_cls_token(inputs):\n","    batch_size = tf.shape(inputs)[0]  # Batch boyutunu dinamik olarak alma\n","    cls_token = cls_dense_layer(tf.zeros((1, 1, embedding_dim)))  # Sabit Dense katmanını kullan\n","    cls_token = tf.tile(cls_token, [batch_size, 1, 1])  # Batch boyutuna göre çoğaltma\n","    return tf.concat([cls_token, inputs], axis=1)  # [CLS] token'ini patch'lere ekleme\n","\n","# Lambda katmanı ile uygulama\n","transformer_input = Lambda(add_cls_token)(patch_embeddings)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:15:18.948919Z","iopub.status.busy":"2025-02-24T13:15:18.948600Z","iopub.status.idle":"2025-02-24T13:15:19.170170Z","shell.execute_reply":"2025-02-24T13:15:19.169451Z","shell.execute_reply.started":"2025-02-24T13:15:18.948893Z"},"trusted":true},"outputs":[],"source":["# Transformer Encoder katmanı\n","class TransformerEncoder(Layer):\n","    def __init__(self, num_heads, ff_dim, **kwargs):\n","        super(TransformerEncoder, self).__init__(**kwargs)\n","        self.num_heads = num_heads\n","        self.ff_dim = ff_dim\n","        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n","        self.ffn = tf.keras.Sequential([\n","            Dense(ff_dim, activation='relu'),\n","            Dense(embedding_dim)\n","        ])\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","\n","    def call(self, inputs):\n","        attn_output = self.attention(inputs, inputs)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","\n","# Transformer encoder'ı uygulama\n","transformer_output = TransformerEncoder(num_heads=8, ff_dim=512)(transformer_input)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:15:21.842390Z","iopub.status.busy":"2025-02-24T13:15:21.842025Z","iopub.status.idle":"2025-02-24T13:15:21.876656Z","shell.execute_reply":"2025-02-24T13:15:21.875817Z","shell.execute_reply.started":"2025-02-24T13:15:21.842341Z"},"trusted":true},"outputs":[],"source":["# [CLS] token'ini kullanarak sınıflandırma\n","cls_output = transformer_output[:, 0, :]  # (batch_size, embedding_dim)\n","\n","# Sınıflandırma katmanları\n","x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(cls_output)\n","x = Dense(256, kernel_regularizer=regularizers.l2(0.016), \n","          activity_regularizer=regularizers.l1(0.006),\n","          bias_regularizer=regularizers.l1(0.006), activation='relu')(x)\n","x = Dropout(rate=0.45, seed=123)(x)\n","outputs = Dense(class_count, activation='softmax')(x)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:15:24.624043Z","iopub.status.busy":"2025-02-24T13:15:24.623714Z","iopub.status.idle":"2025-02-24T13:15:24.667142Z","shell.execute_reply":"2025-02-24T13:15:24.666278Z","shell.execute_reply.started":"2025-02-24T13:15:24.624016Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">785</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ transformer_encoder                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">785</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">659,712</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lambda (\u001b[38;5;33mLambda\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m785\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ transformer_encoder                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m785\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m659,712\u001b[0m │\n","│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ get_item (\u001b[38;5;33mGetItem\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │           \u001b[38;5;34m2,056\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">788,552</span> (3.01 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m788,552\u001b[0m (3.01 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">788,296</span> (3.01 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m788,296\u001b[0m (3.01 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["# Tam modeli oluşturma\n","full_model = Model(inputs=inputs, outputs=outputs)\n","\n","# Modeli derleme\n","full_model.compile(optimizer=Adamax(learning_rate=0.001), \n","                   loss='categorical_crossentropy', \n","                   metrics=['accuracy'])\n","# Model özetini yazdırma\n","full_model.summary()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:15:29.165343Z","iopub.status.busy":"2025-02-24T13:15:29.165009Z","iopub.status.idle":"2025-02-24T13:17:21.255216Z","shell.execute_reply":"2025-02-24T13:17:21.253820Z","shell.execute_reply.started":"2025-02-24T13:15:29.165305Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n","Training started. Initial learning rate: 0.0010000000474974513\n","Epoch 1/40 started\n","1/  40     5.1318    0.428   13.4016   0.449  0.001000 0.001000  accuracy    0.00    96.86  \n","Epoch 2/40 started\n","                    processing batch 59 of 128  -   accuracy=  44.250   -   loss:  4.35154 \r"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-e587fd0aa6de>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m             factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m history = full_model.fit(x=train_gen, epochs=epochs, verbose=0, callbacks=callbacks,\n\u001b[0m\u001b[1;32m      7\u001b[0m                          validation_data=valid_gen, validation_steps=None, shuffle=False)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Eğitim\n","# Örnek callbacks \n","callbacks = [MyCallback(model= full_model, patience= patience, stop_patience= stop_patience, threshold= threshold,\n","            factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]\n","\n","history = full_model.fit(x=train_gen, epochs=epochs, verbose=0, callbacks=callbacks,\n","                         validation_data=valid_gen, validation_steps=None, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:00:19.372293Z","iopub.status.busy":"2025-02-24T13:00:19.371970Z","iopub.status.idle":"2025-02-24T13:00:19.976429Z","shell.execute_reply":"2025-02-24T13:00:19.975500Z","shell.execute_reply.started":"2025-02-24T13:00:19.372269Z"},"trusted":true},"outputs":[],"source":["plot_training(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:00:23.644545Z","iopub.status.busy":"2025-02-24T13:00:23.644259Z","iopub.status.idle":"2025-02-24T13:00:41.789327Z","shell.execute_reply":"2025-02-24T13:00:41.788665Z","shell.execute_reply.started":"2025-02-24T13:00:23.644523Z"},"trusted":true},"outputs":[],"source":["ts_length = len(test_df)\n","test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n","test_steps = ts_length // test_batch_size\n","\n","train_score = full_model.evaluate(train_gen, steps= test_steps, verbose= 1)\n","valid_score = full_model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n","test_score = full_model.evaluate(test_gen, steps= test_steps, verbose= 1)\n","\n","print(\"Train Loss: \", train_score[0])\n","print(\"Train Accuracy: \", train_score[1])\n","print('-' * 20)\n","print(\"Validation Loss: \", valid_score[0])\n","print(\"Validation Accuracy: \", valid_score[1])\n","print('-' * 20)\n","print(\"Test Loss: \", test_score[0])\n","print(\"Test Accuracy: \", test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:00:55.769649Z","iopub.status.busy":"2025-02-24T13:00:55.769329Z","iopub.status.idle":"2025-02-24T13:01:07.219952Z","shell.execute_reply":"2025-02-24T13:01:07.219087Z","shell.execute_reply.started":"2025-02-24T13:00:55.769594Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","# ROC ve AUC çizimi için fonksiyon\n","def plot_roc_auc(y_test, y_pred_probs, class_count):\n","    if len(y_test.shape) == 1:\n","        y_true_onehot = tf.keras.utils.to_categorical(y_test, num_classes=class_count)\n","    else:\n","        y_true_onehot = y_test\n","    \n","    fpr = {}\n","    tpr = {}\n","    roc_auc = {}\n","    for i in range(class_count):\n","        fpr[i], tpr[i], _ = roc_curve(y_true_onehot[:, i], y_pred_probs[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","    \n","    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_onehot.ravel(), y_pred_probs.ravel())\n","    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","    \n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(class_count)]))\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for i in range(class_count):\n","        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","    mean_tpr /= class_count\n","    fpr[\"macro\"] = all_fpr\n","    tpr[\"macro\"] = mean_tpr\n","    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","    \n","    plt.figure(figsize=(10, 8))\n","    for i in range(class_count):\n","        plt.plot(fpr[i], tpr[i], label=f'Sınıf {i} (AUC = {roc_auc[i]:.2f})')\n","    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Mikro-ortalama (AUC = {roc_auc[\"micro\"]:.2f})', linestyle='--')\n","    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'Makro-ortalama (AUC = {roc_auc[\"macro\"]:.2f})', linestyle='--')\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Yanlış Pozitif Oranı')\n","    plt.ylabel('Doğru Pozitif Oranı')\n","    plt.title('ConvIT ROC Eğrisi')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","# Batch bazında tahmin yapma\n","preds = []\n","y_test = []\n","steps = len(test_gen)  # Test setindeki batch sayısı\n","for i, (batch_x, batch_y) in enumerate(test_gen):\n","    if i >= steps:\n","        break\n","    batch_preds = full_model.predict(batch_x, verbose=0)  # Her batch için tahmin\n","    preds.append(batch_preds)\n","    y_test.append(batch_y)\n","\n","preds = np.concatenate(preds, axis=0)\n","y_test = np.concatenate(y_test, axis=0)\n","\n","y_pred = np.argmax(preds, axis=1)\n","print(\"Tahmin edilen sınıf indeksleri:\", y_pred)\n","\n","# ROC ve AUC çizimi\n","plot_roc_auc(y_test, preds, class_count=len(list(train_gen.class_indices.keys())))  # Sınıf sayınızı buraya girin"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-24T13:01:56.853707Z","iopub.status.busy":"2025-02-24T13:01:56.853366Z","iopub.status.idle":"2025-02-24T13:01:57.400057Z","shell.execute_reply":"2025-02-24T13:01:57.399250Z","shell.execute_reply.started":"2025-02-24T13:01:56.853679Z"},"trusted":true},"outputs":[],"source":["g_dict = test_gen.class_indices\n","classes = list(g_dict.keys())\n","\n","# Confusion matrix\n","cm = confusion_matrix(test_gen.classes, y_pred)\n","plot_confusion_matrix(cm= cm, classes= classes, title = 'Confusion Matrix')\n","\n","# Classification report\n","print(classification_report(test_gen.classes, y_pred, target_names= classes))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":611716,"sourceId":1512919,"sourceType":"datasetVersion"},{"datasetId":2440665,"sourceId":4130910,"sourceType":"datasetVersion"},{"datasetId":2719985,"sourceId":4700752,"sourceType":"datasetVersion"},{"datasetId":3255852,"sourceId":5664310,"sourceType":"datasetVersion"},{"datasetId":4957209,"sourceId":8345190,"sourceType":"datasetVersion"}],"dockerImageVersionId":30919,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
